import React, { useState, useEffect, useRef, useCallback } from "react";
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Alert,
  ActivityIndicator,
  Modal,
  Text,
  Platform,
  ScrollView,
  SafeAreaView,
} from "react-native";
import { MaterialCommunityIcons } from "@expo/vector-icons";
import {
  useNavigation,
  useRoute,
  useFocusEffect,
} from "@react-navigation/native";
import { Audio } from "expo-av";
import Slider from "@react-native-community/slider";
import * as FileSystem from "expo-file-system";
import * as Clipboard from "expo-clipboard";
import * as Sharing from "expo-sharing";

import colors from "../config/colors";
import AppText from "../components/Text";
import SecondaryButton from "../components/SecondaryButton";
import CustomCard from "../components/CustomCard";
import { ensureWhisperModel } from "../services/whisperModel";
import { initWhisper } from "whisper.rn";
//////////////

/**
 * TranscriptionScreen Component
 *
 * This screen handles:
 * 1. Audio playback of recorded files
 * 2. AI-powered transcription using Whisper model
 * 3. Text editing and sharing capabilities
 * 4. Navigation to summary screen
 */
export default function TranscriptionScreen() {
  // Navigation hooks for screen transitions
  const navigation = useNavigation();
  const route = useRoute();

  // Extract the audio file URI from navigation params
  const recordingUri = route.params?.uri;

  // === STATE VARIABLES ===

  // Loading states
  const [loading, setLoading] = useState(false);
  const [downloadProgress, setDownloadProgress] = useState(0);
  const [downloadStatus, setDownloadStatus] = useState(""); // Status message for user
  const [isDownloading, setIsDownloading] = useState(false);

  // Audio playback states
  const [soundObj, setSoundObj] = useState(null); // Audio.Sound instance
  const [durationMillis, setDurationMillis] = useState(0); // Total audio duration
  const [positionMillis, setPositionMillis] = useState(0); // Current playback position
  const [isPlaying, setIsPlaying] = useState(false); // Playback state

  // Transcription state
  const [transcribedText, setTranscribedText] = useState(""); // AI-generated transcript

  // Whisper AI model reference
  const whisperRef = useRef(null);

  // === RELOAD PREVENTION GUARDS ===
  // These refs prevent infinite reload loops when handling audio files
  const isReloadingRef = useRef(false); // Flag to prevent concurrent reloads
  const lastSrcRef = useRef(null); // Cache last loaded source URI
  const lastSizeRef = useRef(null); // Cache last file size for comparison

  // === CLEANUP ON COMPONENT UNMOUNT ===
  useEffect(() => {
    return () => {
      // Clean up Whisper model instance when component unmounts
      if (whisperRef.current) {
        try {
          whisperRef.current.release?.();
        } catch (error) {
          console.warn("Error releasing Whisper:", error);
        }
        whisperRef.current = null;
      }
    };
  }, []);

  /**
   * Audio Reload Function
   *
   * Handles loading/reloading audio files with smart caching to prevent
   * unnecessary reloads of the same file
   */
  const reloadAudio = useCallback(async () => {
    // Guard against missing URI or concurrent reloads
    if (!recordingUri || isReloadingRef.current) return;
    isReloadingRef.current = true;

    // Ensure file URI has proper protocol prefix
    const src = recordingUri.startsWith("file://")
      ? recordingUri
      : "file://" + recordingUri;

    try {
      // Verify file exists on device storage
      const info = await FileSystem.getInfoAsync(src);
      if (!info.exists) {
        console.error("Audio file does not exist:", src);
        Alert.alert("Ø®Ø·Ø£", "Ù…Ù„Ù Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯");
        return;
      }

      const size = info?.size ?? 0;

      // Skip reload if same file is already loaded (optimization)
      if (
        lastSrcRef.current === src &&
        lastSizeRef.current === size &&
        soundObj
      ) {
        isReloadingRef.current = false;
        return;
      }

      // Reset playback states before loading new audio
      setIsPlaying(false);
      setPositionMillis(0);
      setDurationMillis(0);

      // Clean up previous audio instance
      if (soundObj) {
        try {
          soundObj.setOnPlaybackStatusUpdate(null);
          await soundObj.unloadAsync();
        } catch (error) {
          console.warn("Error unloading previous sound:", error);
        }
        setSoundObj(null);
      }

      // Create temporary copy for playback (some platforms require this)
      const dest = `${FileSystem.cacheDirectory}play_${Date.now()}.wav`;
      await FileSystem.copyAsync({ from: src, to: dest });

      // Create new Audio.Sound instance with status callback
      const { sound } = await Audio.Sound.createAsync(
        { uri: dest },
        { shouldPlay: false },
        (status) => {
          // Update UI with playback status changes
          if (status.isLoaded) {
            setPositionMillis(status.positionMillis || 0);
            setIsPlaying(!!status.isPlaying);
            if (status.durationMillis != null) {
              setDurationMillis(status.durationMillis);
            }
          }
        }
      );

      // Store sound instance and get initial status
      setSoundObj(sound);
      const status = await sound.getStatusAsync();
      if (status.isLoaded) {
        setDurationMillis(status.durationMillis || 0);
        setPositionMillis(status.positionMillis || 0);
      }

      // Cache current file info to prevent unnecessary reloads
      lastSrcRef.current = src;
      lastSizeRef.current = size;
    } catch (error) {
      console.error("Audio reload error:", error);
      Alert.alert("Ø®Ø·Ø£", "ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª");
    } finally {
      isReloadingRef.current = false;
    }
  }, [recordingUri, soundObj]);

  // Reload audio when screen comes into focus
  useFocusEffect(
    useCallback(() => {
      reloadAudio();
    }, [reloadAudio])
  );

  // Clean up audio when component unmounts
  useEffect(() => {
    return () => {
      if (soundObj) {
        try {
          soundObj.setOnPlaybackStatusUpdate(null);
          soundObj.unloadAsync();
        } catch (error) {
          console.warn("Error cleaning up sound:", error);
        }
      }
    };
  }, [soundObj]);

  /**
   * Audio Playback Control
   *
   * Toggles between play and pause states
   */
  const handlePlayPause = async () => {
    if (!soundObj) return;

    try {
      const status = await soundObj.getStatusAsync();
      if (!status.isLoaded) {
        console.warn("Sound not loaded");
        return;
      }

      if (status.isPlaying) {
        await soundObj.pauseAsync();
        setIsPlaying(false);
      } else {
        await soundObj.playAsync();
        setIsPlaying(true);
      }
    } catch (error) {
      console.error("Error in play/pause:", error);
      Alert.alert("Ø®Ø·Ø£", "ÙØ´Ù„ ÙÙŠ ØªØ´ØºÙŠÙ„/Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØµÙˆØª");
    }
  };

  /**
   * Audio Seeking
   *
   * Allows user to jump to specific position in audio
   */
  const handleSeek = async (value) => {
    if (soundObj) {
      try {
        await soundObj.setPositionAsync(value);
      } catch (error) {
        console.error("Error seeking:", error);
      }
    }
  };

  /**
   * Time Formatting Utility
   *
   * Converts milliseconds to MM:SS format
   */
  const formatTime = (millis) => {
    const total = Math.floor((millis || 0) / 1000);
    const mins = Math.floor(total / 60);
    const secs = total % 60;
    return `${mins}:${secs < 10 ? "0" : ""}${secs}`;
  };

  /**
   * AI Transcription Handler with Enhanced Error Handling
   *
   * Main function that:
   * 1. Checks network connectivity
   * 2. Downloads Whisper AI model if needed (with retry logic)
   * 3. Initializes the AI engine
   * 4. Processes audio file to extract text
   * 5. Displays results to user
   */
  const handleTranscribePress = async () => {
    if (!recordingUri) {
      Alert.alert("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ³Ø¬ÙŠÙ„", "ÙŠØ±Ø¬Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø£ÙˆÙ„Ø§Ù‹");
      return;
    }

    // Verify audio file exists before proceeding
    try {
      const fileUri = recordingUri.startsWith("file://")
        ? recordingUri
        : "file://" + recordingUri;
      const info = await FileSystem.getInfoAsync(fileUri);
      if (!info.exists) {
        Alert.alert("Ø®Ø·Ø£", "Ù…Ù„Ù Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯");
        return;
      }
      console.log("Audio file exists, size:", info.size, "bytes");
    } catch (error) {
      console.error("Error checking file:", error);
      Alert.alert("Ø®Ø·Ø£", "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„Ù Ø§Ù„ØµÙˆØª");
      return;
    }

    setLoading(true);
    setDownloadProgress(0);
    setDownloadStatus("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ±...");

    try {
      // Check if Whisper library is available
      setDownloadStatus("Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...");
      if (!initWhisper || typeof initWhisper !== "function") {
        throw new Error("WHISPER_NOT_AVAILABLE");
      }

      // Check network connectivity first
      setDownloadStatus("Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª...");
      const isConnected = await testNetworkConnection();

      if (!isConnected) {
        throw new Error(
          "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"
        );
      }

      // Clean up any existing Whisper instance
      if (whisperRef.current) {
        try {
          whisperRef.current.release?.();
        } catch (e) {
          console.warn("Error releasing previous whisper instance:", e);
        }
        whisperRef.current = null;
      }

      console.log("Ensuring Whisper model...");
      setDownloadStatus("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...");
      setIsDownloading(true);

      // Download AI model with progress tracking and retry logic
      let retryCount = 0;
      const maxRetries = 3;
      let modelPath;

      while (retryCount < maxRetries) {
        try {
          modelPath = await ensureWhisperModel((progress) => {
            console.log("Model download progress:", progress + "%");
            setDownloadProgress(progress);

            // Update status message based on progress
            if (progress < 10) {
              setDownloadStatus("Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù…ÙŠÙ„...");
            } else if (progress < 50) {
              setDownloadStatus(`Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„... ${Math.round(progress)}%`);
            } else if (progress < 90) {
              setDownloadStatus(`Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„... ${Math.round(progress)}%`);
            } else {
              setDownloadStatus("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù...");
            }
          });
          break; // Success, exit retry loop
        } catch (error) {
          retryCount++;
          console.error(
            `Download attempt ${retryCount} failed:`,
            error.message
          );

          if (retryCount < maxRetries) {
            setDownloadStatus(
              `ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ Ù…Ø­Ø§ÙˆÙ„Ø© ${retryCount + 1} Ù…Ù† ${maxRetries}...`
            );
            await new Promise((resolve) => setTimeout(resolve, 2000)); // Wait 2 seconds before retry
          } else {
            throw new Error(
              `ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ ${maxRetries} Ù…Ø­Ø§ÙˆÙ„Ø§Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª`
            );
          }
        }
      }

      setIsDownloading(false);
      setDownloadStatus("Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...");

      console.log("Model path:", modelPath);

      // Verify downloaded model file
      const modelInfo = await FileSystem.getInfoAsync("file://" + modelPath);
      if (!modelInfo.exists) {
        throw new Error("Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„");
      }
      console.log("Model file verified, size:", modelInfo.size, "bytes");

      console.log("Initializing Whisper with model...");

      // Initialize Whisper AI engine with error handling
      const whisperOptions = {
        filePath: modelPath,
      };

      console.log("Whisper init options:", whisperOptions);

      try {
        whisperRef.current = await initWhisper(whisperOptions);
        console.log("Whisper initialized successfully");
      } catch (initError) {
        console.error("Whisper initialization error:", initError);
        if (
          initError.message &&
          initError.message.includes("UnsatisfiedLinkError")
        ) {
          throw new Error("NATIVE_LIBRARY_ERROR");
        }
        throw initError;
      }

      // Prepare audio file for processing
      const audioPath = recordingUri.replace(/^file:\/\//, "");
      console.log("Starting transcription for audio:", audioPath);

      setDownloadStatus("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª...");

      // Configure transcription for Arabic language
      const transcribeOptions = {
        language: "ar", // Arabic language code
      };

      console.log("Transcription options:", transcribeOptions);

      // Start AI transcription process
      const { promise } = whisperRef.current.transcribe(
        audioPath,
        transcribeOptions
      );

      setDownloadStatus("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ...");
      const { result } = await promise;

      // Process and display results
      if (result && result.trim()) {
        console.log("Transcription successful:", result.length, "characters");
        console.log("First 100 chars:", result.substring(0, 100));
        setTranscribedText(result.trim());
        setDownloadStatus("ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­!");
      } else {
        console.warn("Empty transcription result");
        Alert.alert("ØªØ­Ø°ÙŠØ±", "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø£Ùˆ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙØ§Ø±Øº");
      }
    } catch (error) {
      console.error("Transcription error details:", {
        message: error.message,
        stack: error.stack,
        name: error.name,
      });

      // Clean up on error
      if (whisperRef.current) {
        try {
          whisperRef.current.release?.();
        } catch (e) {
          console.warn("Error releasing whisper on error:", e);
        }
        whisperRef.current = null;
      }

      // Show user-friendly error message based on error type
      let errorMessage = "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙØ±ÙŠØº";
      let showTechnicalInfo = false;

      if (error.message === "WHISPER_NOT_AVAILABLE") {
        errorMessage =
          "Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚";
        showTechnicalInfo = true;
      } else if (error.message === "NATIVE_LIBRARY_ERROR") {
        errorMessage = "Ø®Ø·Ø£ ÙÙŠ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠØ©";
        showTechnicalInfo = true;
      } else if (
        error.message &&
        error.message.includes("UnsatisfiedLinkError")
      ) {
        errorMessage = "Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…Ø«Ø¨ØªØ© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­";
        showTechnicalInfo = true;
      } else if (
        error.message &&
        error.message.includes("Unable to resolve host")
      ) {
        errorMessage =
          "ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª";
      } else if (
        error.message &&
        error.message.includes("No address associated with hostname")
      ) {
        errorMessage = "Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹";
      }

      if (showTechnicalInfo) {
        Alert.alert(
          "Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ",
          errorMessage +
            "\n\nÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØªØ«Ø¨ÙŠØªÙ‡ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø±Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø©",
          [
            {
              text: "Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø©",
              onPress: () => {
                // Allow user to retry
              },
            },
            {
              text: "Ù…ÙˆØ§ÙÙ‚",
              style: "default",
            },
          ]
        );
      } else {
        Alert.alert("ÙØ´Ù„", errorMessage);
      }
    } finally {
      setLoading(false);
      setIsDownloading(false);
      setDownloadProgress(0);
      setDownloadStatus("");
    }
  };

  /**
   * Navigation to Summary Screen
   *
   * Passes transcribed text to next screen for AI summarization
   */
  const handleNavigateToSummary = () => {
    if (!transcribedText?.trim()) {
      Alert.alert("âš ï¸", "ÙŠØ±Ø¬Ù‰ ØªÙØ±ÙŠØº Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹");
      return;
    }
    navigation.navigate("Summary", {
      transcribedText: transcribedText.trim(),
      audioUri: recordingUri,
    });
  };

  /**
   * Copy Text to Clipboard
   *
   * Allows user to copy transcribed text for use in other apps
   */
  const handleCopyText = async () => {
    if (!transcribedText?.trim()) {
      Alert.alert("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„Ù†Ø³Ø®");
      return;
    }

    try {
      await Clipboard.setStringAsync(transcribedText);
      Alert.alert("ğŸ“‹", "ØªÙ… Ù†Ø³Ø® Ø§Ù„Ù†Øµ");
    } catch (error) {
      console.error("Copy error:", error);
      Alert.alert("Ø®Ø·Ø£", "ÙØ´Ù„ ÙÙŠ Ù†Ø³Ø® Ø§Ù„Ù†Øµ");
    }
  };

  /**
   * Share Text Function
   *
   * Creates a text file and shares it via system share menu
   */
  const handleShareText = async () => {
    if (!transcribedText?.trim()) {
      Alert.alert("ØªØ­Ø°ÙŠØ±", "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ©");
      return;
    }

    try {
      // Create temporary text file
      const path = `${FileSystem.cacheDirectory}transcript_${Date.now()}.txt`;
      await FileSystem.writeAsStringAsync(path, transcribedText);

      // Share via system share sheet
      if (await Sharing.isAvailableAsync()) {
        await Sharing.shareAsync(path, {
          mimeType: "text/plain",
          dialogTitle: "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Øº",
        });
      } else {
        Alert.alert("Ø®Ø·Ø£", "Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ù‡Ø§Ø²");
      }
    } catch (error) {
      console.error("Share error:", error);
      Alert.alert("Ø®Ø·Ø£", "ÙØ´Ù„ ÙÙŠ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù†Øµ");
    }
  };

  /**
   * Simple Network Test
   *
   * Tests connectivity by making a simple fetch request
   */
  const testNetworkConnection = async () => {
    try {
      // Try to fetch a small resource with timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000); // 5 second timeout

      await fetch("https://www.google.com", {
        method: "HEAD",
        signal: controller.signal,
      });

      clearTimeout(timeoutId);
      return true;
    } catch (error) {
      console.warn("Network test failed:", error.message);
      return false;
    }
  };

  /**
   * Custom Progress Bar Component
   *
   * Safe implementation that avoids native crashes
   */
  const CustomProgressBar = ({ progress }) => {
    const progressWidth = Math.max(0, Math.min(100, progress));

    return (
      <View style={styles.progressBarContainer}>
        <View style={styles.progressBarBackground}>
          <View
            style={[styles.progressBarFill, { width: `${progressWidth}%` }]}
          />
        </View>
      </View>
    );
  };

  // === RENDER UI ===
  return (
    <SafeAreaView style={styles.container}>
      <ScrollView
        contentContainerStyle={styles.scrollContent}
        keyboardShouldPersistTaps="handled"
      >
        {/* Loading Modal with Progress */}
        <Modal transparent visible={loading} animationType="fade">
          <View style={styles.overlay}>
            <View style={styles.loadingContainer}>
              <ActivityIndicator size="large" color={colors.primary} />
              <Text style={styles.statusText}>{downloadStatus}</Text>

              {/* Show progress bar during download */}
              {isDownloading && (
                <View style={styles.progressContainer}>
                  <CustomProgressBar progress={downloadProgress} />
                  <Text style={styles.progressText}>
                    {Math.round(downloadProgress)}%
                  </Text>
                </View>
              )}
            </View>
          </View>
        </Modal>

        {/* Screen Title */}
        <AppText style={styles.header}>Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ø¬ØªÙ…Ø§Ø¹Ùƒ</AppText>

        {/* Audio Player Controls */}
        <View style={styles.audioControls}>
          {/* Play/Pause Button */}
          <TouchableOpacity onPress={handlePlayPause} disabled={!soundObj}>
            <MaterialCommunityIcons
              name={isPlaying ? "pause-circle-outline" : "play-circle-outline"}
              size={50}
              color={soundObj ? colors.secondary : "#ccc"}
            />
          </TouchableOpacity>

          {/* Audio Scrubber and Time Display */}
          <View style={styles.sliderWrapper}>
            <Slider
              style={{ flex: 1 }}
              value={positionMillis}
              minimumValue={0}
              maximumValue={durationMillis || 1}
              onSlidingComplete={handleSeek}
              minimumTrackTintColor={colors.secondary}
              maximumTrackTintColor="#ccc"
              thumbTintColor={colors.secondary}
              disabled={!soundObj}
            />
            <View style={styles.timeRow}>
              <AppText style={styles.timeText}>
                {formatTime(positionMillis)}
              </AppText>
              <AppText style={styles.timeText}>
                {formatTime(durationMillis)}
              </AppText>
            </View>
          </View>
        </View>

        {/* Transcribed Text Card with Actions */}
        <CustomCard
          title="Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Øº"
          value={transcribedText}
          onChangeText={setTranscribedText}
          placeholder="Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Øº Ø³ÙŠØ¸Ù‡Ø± Ù‡Ù†Ø§..."
          height={200}
          items={[
            {
              icon: "content-copy",
              color: colors.secondary,
              onPress: handleCopyText,
            },
            {
              icon: "share-variant",
              color: colors.secondary,
              onPress: handleShareText,
            },
          ]}
        />

        {/* Action Buttons */}
        <View style={styles.bottomButtons}>
          <SecondaryButton
            text="ØªÙØ±ÙŠØº Ø§Ù„Ù†Øµ"
            color={colors.secondary}
            onPress={handleTranscribePress}
            disabled={loading || !recordingUri}
          />
          <SecondaryButton
            text="Ø§Ù„Ø°Ù‡Ø§Ø¨ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ø®Øµ"
            color={colors.secondary}
            onPress={handleNavigateToSummary}
            disabled={!transcribedText?.trim()}
          />
        </View>
      </ScrollView>
    </SafeAreaView>
  );
}

// === STYLES ===
const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: "#f2f2f2",
    padding: 20,
  },
  header: {
    fontSize: 25,
    marginBottom: 20,
    alignSelf: "center",
  },
  audioControls: {
    flexDirection: "row",
    alignItems: "center",
    marginBottom: 20,
  },
  sliderWrapper: {
    flex: 1,
    marginHorizontal: 10,
  },
  timeRow: {
    flexDirection: "row",
    justifyContent: "space-between",
    marginTop: 5,
  },
  timeText: {
    fontSize: 12,
    color: "#666",
  },
  bottomButtons: {
    marginBottom: 20,
    alignItems: "stretch",
  },
  overlay: {
    flex: 1,
    justifyContent: "center",
    alignItems: "center",
    backgroundColor: "rgba(0,0,0,0.7)",
  },
  loadingContainer: {
    backgroundColor: "white",
    padding: 30,
    borderRadius: 15,
    alignItems: "center",
    minWidth: 250,
    shadowColor: "#000",
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.25,
    shadowRadius: 3.84,
    elevation: 5,
  },
  statusText: {
    marginTop: 15,
    fontSize: 16,
    color: "#333",
    textAlign: "center",
    fontWeight: "500",
  },
  progressContainer: {
    width: "100%",
    marginTop: 20,
    alignItems: "center",
  },
  progressBarContainer: {
    width: "100%",
    height: 8,
    backgroundColor: "#e0e0e0",
    borderRadius: 4,
    overflow: "hidden",
  },
  progressBarBackground: {
    width: "100%",
    height: "100%",
  },
  progressBarFill: {
    height: "100%",
    backgroundColor: "#007AFF", // Use your colors.primary here
    borderRadius: 4,
  },
  progressText: {
    marginTop: 10,
    fontSize: 14,
    color: "#666",
    fontWeight: "bold",
  },
});
